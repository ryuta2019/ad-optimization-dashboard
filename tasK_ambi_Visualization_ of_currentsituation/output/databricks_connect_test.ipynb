{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databricks 接続テスト\n",
    "\n",
    "このNotebookは、ローカル環境からDatabricks Connectを使用してDatabricksクラスターに接続するためのテスト用です。\n",
    "\n",
    "## トークンの使い分けについて（重要）\n",
    "社内ポリシーに基づき、本環境（ローカル開発・個人分析）からの接続には**個人用アクセストークン**を使用してください。\n",
    "\n",
    "> **個人用アクセストークン**\n",
    "> 個人アクセストークンはTableauDesktopなど個人利用する際にお使いください。\n",
    "> 複数人で利用、自部以外の人に共有する際の接続方法としては利用しないでください。\n",
    ">\n",
    "> **アプリケーション用アクセストークン**\n",
    "> アプリケーションからDatabricksに接続するためのトークンを発行しています。\n",
    "> Dashboardでの共有や自分以外の人にデータを共有する際は各ツール内で設定されている接続情報を利用してください。\n",
    "> (Trocco, Tableau Server等に埋め込まれています)\n",
    "\n",
    "本Notebookでの検証作業は「個人利用」に該当するため、ご自身で発行したトークンをご利用ください。\n",
    "\n",
    "## 事前準備\n",
    "1. `pip install databricks-connect databricks-sdk` が完了していること（requirements.txtに追加済み）\n",
    "2. Databricksの以下の情報を取得していること\n",
    "    - **Workspace URL** (例: `https://adb-xxxx.xx.azuredatabricks.net`)\n",
    "    - **Access Token** (User Settings -> Developer -> Access tokens で生成)\n",
    "    - **Cluster ID** (Compute -> 各クラスターの詳細 -> More info -> Resource ID ではなく Cluster ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.connect import DatabricksSession\n",
    "from databricks.sdk.core import Config\n",
    "\n",
    "# 接続情報を設定してください\n",
    "# 本番環境や共有環境では環境変数やプロファイル(.databrickscfg)を使用することを推奨しますが、\n",
    "# 手元のテストではここに直接入力して確認できます。\n",
    "DATABRICKS_HOST = \"https://<your-workspace-url>\"\n",
    "DATABRICKS_TOKEN = \"<your-personal-access-token>\" # ここには個人用アクセストークンを入力\n",
    "DATABRICKS_CLUSTER_ID = \"<your-cluster-id>\"\n",
    "\n",
    "# 環境変数にセット（Databricks Connectが参照します）\n",
    "os.environ['DATABRICKS_HOST'] = DATABRICKS_HOST\n",
    "os.environ['DATABRICKS_TOKEN'] = DATABRICKS_TOKEN\n",
    "os.environ['DATABRICKS_CLUSTER_ID'] = DATABRICKS_CLUSTER_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparkセッションの作成\n",
    "spark = DatabricksSession.builder.getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡単なDataFrame操作のテスト\n",
    "try:\n",
    "    df = spark.range(10)\n",
    "    print(\"Generated DataFrame:\")\n",
    "    df.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLクエリのテスト\n",
    "try:\n",
    "    # catalogsのリストを取得してみる\n",
    "    spark.sql(\"SHOW CATALOGS\").show()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}