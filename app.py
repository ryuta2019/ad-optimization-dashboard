import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pymc as pm
import arviz as az
from pygam import LinearGAM, s
from scipy.optimize import minimize
from sklearn.metrics import r2_score
import warnings
import hashlib
warnings.filterwarnings('ignore')

# ========================================
# èªè¨¼æ©Ÿèƒ½
# ========================================

def hash_password(password):
    """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’SHA-256ã§ãƒãƒƒã‚·ãƒ¥åŒ–"""
    return hashlib.sha256(password.encode()).hexdigest()

def check_login(username, password):
    """ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼ãƒã‚§ãƒƒã‚¯"""
    # æŒ‡å®šã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
    default_users = {
        "npochamu": hash_password("kimimaro")
    }
    
    # st.secretsãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãã¡ã‚‰ã‚’å„ªå…ˆ
    try:
        users = st.secrets.get("auth", {}).get("users", default_users)
    except:
        users = default_users
    
    hashed_input = hash_password(password)
    
    if username in users and users[username] == hashed_input:
        return True
    return False

def login_form():
    """ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º"""
    st.markdown("""
    <style>
    .login-container {
        max-width: 400px;
        margin: 100px auto;
        padding: 2rem;
        background: white;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .login-header {
        text-align: center;
        font-size: 2rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 2rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown('<div class="login-header">ğŸ” ãƒ­ã‚°ã‚¤ãƒ³</div>', unsafe_allow_html=True)
        
        with st.form("login_form"):
            username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å", key="login_username")
            password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="login_password")
            submit = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³", use_container_width=True)
            
            if submit:
                if username and password:
                    if check_login(username, password):
                        st.session_state.authenticated = True
                        st.session_state.username = username
                        st.success("âœ… ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸï¼")
                        st.rerun()
                    else:
                        st.error("âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
                else:
                    st.warning("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")


def logout_button():
    """ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³"""
    if st.sidebar.button("ğŸšª ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", key="logout_btn"):
        st.session_state.authenticated = False
        st.session_state.username = None
        st.rerun()

# ========================================
# èªè¨¼çŠ¶æ…‹ã®åˆæœŸåŒ–
# ========================================
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
if 'username' not in st.session_state:
    st.session_state.username = None

# ãƒ­ã‚°ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯
if not st.session_state.authenticated:
    # ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ç”¨ï¼‰
    st.set_page_config(
        page_title="ãƒ­ã‚°ã‚¤ãƒ³ - åºƒå‘Šæœ€é©åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        page_icon="ğŸ”",
        layout="centered"
    )
    login_form()
    st.stop()

# ========================================
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ­ã‚°ã‚¤ãƒ³å¾Œï¼‰
# =======================================

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="åºƒå‘Šå®£ä¼è²»æœ€é©åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #7f8c8d;
        margin-bottom: 2rem;
    }
    .info-box {
        background: #e8f4f8;
        padding: 1rem;
        border-left: 4px solid #3498db;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        padding: 1rem;
        border-left: 4px solid #f39c12;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if 'trained_models' not in st.session_state:
    st.session_state.trained_models = {}
if 'optimization_result' not in st.session_state:
    st.session_state.optimization_result = None
if 'all_channel_results' not in st.session_state:
    st.session_state.all_channel_results = []
if 'combined_df' not in st.session_state:
    st.session_state.combined_df = None
if 'optimization_models' not in st.session_state:
    st.session_state.optimization_models = {}
if 'prophet_scenarios' not in st.session_state:
    st.session_state.prophet_scenarios = {}

# ========================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ï¼ˆé‡è¤‡ãªã—ãƒ»1å›ã®ã¿å®šç¾©ï¼‰
# ========================================

def train_hill_model(x_data, y_data):
    """Hillãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
    with pm.Model() as model:
        slope = pm.HalfNormal('slope', sigma=1)
        EC50 = pm.HalfNormal('EC50', sigma=np.median(x_data[x_data > 0]) if np.any(x_data > 0) else 10000)
        Vmax = pm.Deterministic('Vmax', slope * EC50)
        mu = Vmax * x_data / (EC50 + x_data)
        sigma = pm.HalfNormal('sigma', sigma=y_data.std())
        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_data)
        trace = pm.sample(10000, tune=1000, chains=4, cores=4, target_accept=0.95, progressbar=False, random_seed=42)
    return trace

def train_linear_model(x_data, y_data):
    """ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
    with pm.Model() as linear_model:
        alpha = pm.Normal('alpha', mu=y_data.mean(), sigma=y_data.std() * 2)
        beta = pm.Normal('beta', mu=0, sigma=1)
        mu = alpha + beta * x_data
        sigma = pm.HalfNormal('sigma', sigma=y_data.std())
        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_data)
        trace = pm.sample(10000, tune=1000, chains=4, cores=4, target_accept=0.95, progressbar=False, random_seed=42)
    return trace

def train_gam_model(X_data, y_data):
    """GAMãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
    gam = LinearGAM(s(0, constraints='monotonic_inc')).fit(X_data, y_data)
    return gam

def plot_hill_curve(x_data, y_data, trace, dates, channel_name, target_var):
    """Hillæ›²ç·šã®å¯è¦–åŒ–"""
    vmax_mean = trace.posterior['Vmax'].mean().item()
    ec50_mean = trace.posterior['EC50'].mean().item()
    y_pred = vmax_mean * x_data / (ec50_mean + x_data)
    r2 = r2_score(y_data, y_pred)
    
    x_range = np.linspace(0, x_data.max() * 1.1, 100)
    post_curves = trace.posterior['Vmax'].values.flatten()[:, None] * x_range / (trace.posterior['EC50'].values.flatten()[:, None] + x_range)
    y_mean = post_curves.mean(axis=0)
    hdi_data = az.hdi(post_curves, hdi_prob=0.95)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=np.concatenate([x_range, x_range[::-1]]),
        y=np.concatenate([hdi_data[:, 1], hdi_data[:, 0][::-1]]),
        fill='toself',
        fillcolor='rgba(0,176,246,0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        name='95% ä¿¡ç”¨åŒºé–“',
        hoverinfo='skip'
    ))
    
    fig.add_trace(go.Scatter(
        x=x_range, y=y_mean,
        mode='lines',
        line=dict(color='rgba(0,176,246,0.8)', width=3),
        name='Hillé–¢æ•°æ›²ç·š'
    ))
    
    latest_date = pd.to_datetime(dates).max()
    four_weeks_ago = latest_date - pd.Timedelta(days=27)
    recent_mask = pd.to_datetime(dates) > four_weeks_ago
    past_mask = ~recent_mask
    
    # æ—¥ä»˜ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
    dates_str = pd.to_datetime(dates).strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    if past_mask.any():
        fig.add_trace(go.Scatter(
            x=x_data[past_mask], y=y_data[past_mask],
            mode='markers',
            marker=dict(size=10, color='#636EFA', opacity=0.7),
            name='éå»ã®å®Ÿç¸¾',
            customdata=dates_str[past_mask],
            hovertemplate='<b>éå»ã®å®Ÿç¸¾</b><br>' +
                          'é€±é–‹å§‹æ—¥: %{customdata}<br>' +
                          'åºƒå‘Šå®£ä¼è²»: Â¥%{x:,.0f}<br>' +
                          f'{target_var}: %{{y:,.0f}}<br>' +
                          '<extra></extra>'
        ))
    
    if recent_mask.any():
        fig.add_trace(go.Scatter(
            x=x_data[recent_mask], y=y_data[recent_mask],
            mode='markers',
            marker=dict(symbol='star', size=15, color='gold', line=dict(width=1, color='black')),
            name='ç›´è¿‘4é€±é–“ã®å®Ÿç¸¾',
            customdata=dates_str[recent_mask],
            hovertemplate='<b>ç›´è¿‘4é€±é–“ã®å®Ÿç¸¾</b><br>' +
                          'é€±é–‹å§‹æ—¥: %{customdata}<br>' +
                          'åºƒå‘Šå®£ä¼è²»: Â¥%{x:,.0f}<br>' +
                          f'{target_var}: %{{y:,.0f}}<br>' +
                          '<extra></extra>'
        ))
    
    fig.update_layout(
        title=f"{channel_name}: åºƒå‘Šè²»ã¨{target_var}ã®é–¢ä¿‚",
        xaxis_title='åºƒå‘Šå®£ä¼è²»',
        yaxis_title=target_var,
        hovermode='x unified',
        template='plotly_white',
        height=500,
        showlegend=True
    )
    
    fig.add_annotation(
        x=0.98, y=0.05,
        xref='paper', yref='paper',
        text=f'<b>RÂ²: {r2:.3f}</b>',
        showarrow=False,
        font=dict(size=14),
        bgcolor='rgba(255, 255, 255, 0.7)',
        bordercolor='#3498db',
        borderwidth=1
    )
    
    return fig, r2

def plot_linear_curve(x_data, y_data, trace, dates, channel_name, target_var):
    """ç·šå½¢å›å¸°æ›²ç·šã®å¯è¦–åŒ–"""
    alpha_mean = trace.posterior['alpha'].mean().item()
    beta_mean = trace.posterior['beta'].mean().item()
    y_pred = alpha_mean + beta_mean * x_data
    r2 = r2_score(y_data, y_pred)
    
    x_range = np.linspace(0, x_data.max() * 1.1, 100)
    alpha_post = trace.posterior['alpha'].values.flatten()
    beta_post = trace.posterior['beta'].values.flatten()
    post_curves = alpha_post[:, None] + beta_post[:, None] * x_range
    y_mean = post_curves.mean(axis=0)
    hdi_data = az.hdi(post_curves, hdi_prob=0.95)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=np.concatenate([x_range, x_range[::-1]]),
        y=np.concatenate([hdi_data[:, 1], hdi_data[:, 0][::-1]]),
        fill='toself',
        fillcolor='rgba(0,176,246,0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        name='95% ä¿¡ç”¨åŒºé–“',
        hoverinfo='skip'
    ))
    
    fig.add_trace(go.Scatter(
        x=x_range, y=y_mean,
        mode='lines',
        line=dict(color='rgba(0,176,246,0.8)', width=3),
        name='ç·šå½¢å›å¸°ç›´ç·š'
    ))
    
    latest_date = pd.to_datetime(dates).max()
    four_weeks_ago = latest_date - pd.Timedelta(days=27)
    recent_mask = pd.to_datetime(dates) > four_weeks_ago
    past_mask = ~recent_mask
    
    # æ—¥ä»˜ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
    dates_str = pd.to_datetime(dates).strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    if past_mask.any():
        fig.add_trace(go.Scatter(
            x=x_data[past_mask], y=y_data[past_mask],
            mode='markers',
            marker=dict(size=10, color='#636EFA', opacity=0.7),
            name='éå»ã®å®Ÿç¸¾',
            customdata=dates_str[past_mask],
            hovertemplate='<b>éå»ã®å®Ÿç¸¾</b><br>' +
                          'é€±é–‹å§‹æ—¥: %{customdata}<br>' +
                          'åºƒå‘Šå®£ä¼è²»: Â¥%{x:,.0f}<br>' +
                          f'{target_var}: %{{y:,.0f}}<br>' +
                          '<extra></extra>'
        ))
    
    if recent_mask.any():
        fig.add_trace(go.Scatter(
            x=x_data[recent_mask], y=y_data[recent_mask],
            mode='markers',
            marker=dict(symbol='star', size=15, color='gold', line=dict(width=1, color='black')),
            name='ç›´è¿‘4é€±é–“ã®å®Ÿç¸¾',
            customdata=dates_str[recent_mask],
            hovertemplate='<b>ç›´è¿‘4é€±é–“ã®å®Ÿç¸¾</b><br>' +
                          'é€±é–‹å§‹æ—¥: %{customdata}<br>' +
                          'åºƒå‘Šå®£ä¼è²»: Â¥%{x:,.0f}<br>' +
                          f'{target_var}: %{{y:,.0f}}<br>' +
                          '<extra></extra>'
        ))
    
    fig.update_layout(
        title=f"{channel_name}: åºƒå‘Šè²»ã¨{target_var}ã®é–¢ä¿‚",
        xaxis_title='åºƒå‘Šå®£ä¼è²»',
        yaxis_title=target_var,
        hovermode='x unified',
        template='plotly_white',
        height=500,
        showlegend=True
    )
    
    fig.add_annotation(
        x=0.98, y=0.05,
        xref='paper', yref='paper',
        text=f'<b>RÂ²: {r2:.3f}</b>',
        showarrow=False,
        font=dict(size=14),
        bgcolor='rgba(255, 255, 255, 0.7)',
        bordercolor='#3498db',
        borderwidth=1
    )
    
    return fig, r2

def plot_combined_hill_curves(all_results, x_range):
    """å…¨åª’ä½“ã®Hillæ›²ç·šã‚’çµ±åˆè¡¨ç¤º"""
    fig = go.Figure()
    
    colors = ['#9b59b6', '#3498db', '#2ecc71', '#e67e22', '#34495e', '#5dade2', '#1abc9c', '#e74c3c']
    
    for i, result in enumerate(all_results):
        channel = result['channel']
        vmax = result['vmax_mean']
        ec50 = result['ec50_mean']
        
        y_pred = vmax * x_range / (ec50 + x_range)
        
        fig.add_trace(go.Scatter(
            x=x_range, y=y_pred,
            mode='lines',
            line=dict(color=colors[i % len(colors)], width=3),
            name=channel
        ))
    
    fig.update_layout(
        title="å…¨åª’ä½“æ¯”è¼ƒ(Hillé–¢æ•°æ›²ç·š)",
        xaxis_title='åºƒå‘Šå®£ä¼è²»',
        yaxis_title='äºˆæ¸¬å¿œå‹Ÿæ•°',
        template='plotly_white',
        height=600,
        hovermode='x unified'
    )
    
    return fig

def analyze_channel(df, channel_name, config):
    """åª’ä½“åˆ†æã®å®Ÿè¡Œï¼ˆç¾çŠ¶æŠŠæ¡ç”¨ï¼‰"""
    start_date = pd.to_datetime(config['start_date'])
    end_date = pd.to_datetime(config['end_date'])
    target_var = config['target_variable']
    model_type = config['model_type']
    
    filtered_df = df[(df['channel'] == channel_name) & 
                     (df['week_start_date'] >= start_date) & 
                     (df['week_start_date'] <= end_date)].copy()
    
    if len(filtered_df) < 5:
        return None, None, None
    
    x_data = filtered_df['total_spend'].values
    y_data = filtered_df[target_var].values
    dates = filtered_df['week_start_date'].values
    
    try:
        if model_type == 'hill':
            trace = train_hill_model(x_data, y_data)
            fig, r2 = plot_hill_curve(x_data, y_data, trace, dates, channel_name, target_var)
            result = {
                'channel': channel_name,
                'model_type': 'hill',
                'vmax_mean': trace.posterior['Vmax'].mean().item(),
                'ec50_mean': trace.posterior['EC50'].mean().item(),
                'r2': r2
            }
        else:  # linear
            trace = train_linear_model(x_data, y_data)
            fig, r2 = plot_linear_curve(x_data, y_data, trace, dates, channel_name, target_var)
            result = {
                'channel': channel_name,
                'model_type': 'linear',
                'alpha_mean': trace.posterior['alpha'].mean().item(),
                'beta_mean': trace.posterior['beta'].mean().item(),
                'r2': r2
            }
        
        return fig, r2, result
    except Exception as e:
        st.error(f"åª’ä½“ {channel_name} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, None

def train_optimization_models(df, config):
    """æŠ•è³‡è²»ç”¨æœ€é©åŒ–ç”¨ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆHill/Linear/GAMå¯¾å¿œï¼‰"""
    model_params = {}
    
    for channel_name, cfg in config.items():
        model_type = cfg.get('model_type', 'linear')
        
        start_date = pd.to_datetime(cfg['start_date'])
        end_date = pd.to_datetime(cfg['end_date'])
        filtered_df = df[(df['channel'] == channel_name) & 
                        (df['week_start_date'] >= start_date) & 
                        (df['week_start_date'] <= end_date)].copy()
        
        if len(filtered_df) < 5:
            continue
        
        x_data = filtered_df['total_spend'].values
        y_data = filtered_df[cfg['target_variable']].values
        X_gam = filtered_df[['total_spend']]
        
        # 0å††ã‚’é™¤å¤–ã—ãŸä¸‹ä½3ã¤ã®å¹³å‡ã‚’æœ€ä½äºˆç®—ã¨ã—ã¦è¨­å®š
        non_zero_spends = filtered_df[filtered_df['total_spend'] > 0]['total_spend'].values
        
        if len(non_zero_spends) >= 3:
            sorted_spends = np.sort(non_zero_spends)
            bottom_3_avg = np.mean(sorted_spends[:3])
            min_budget_constraint = bottom_3_avg
        elif len(non_zero_spends) > 0:
            min_budget_constraint = np.min(non_zero_spends)
        else:
            min_budget_constraint = 1000
        
        min_budget_constraint = max(min_budget_constraint, 1000)
        
        try:
            if model_type == 'hill':
                trace = train_hill_model(x_data, y_data)
                model_params[channel_name] = {
                    'model_type': 'hill',
                    'vmax_mean': trace.posterior['Vmax'].mean().item(),
                    'ec50_mean': trace.posterior['EC50'].mean().item(),
                    'min_spend': min_budget_constraint,
                    'max_spend': filtered_df['total_spend'].max(),
                    'bottom_3_avg': bottom_3_avg if len(non_zero_spends) >= 3 else min_budget_constraint
                }
            elif model_type == 'linear':
                trace = train_linear_model(x_data, y_data)
                model_params[channel_name] = {
                    'model_type': 'linear',
                    'alpha_mean': trace.posterior['alpha'].mean().item(),
                    'beta_mean': trace.posterior['beta'].mean().item(),
                    'min_spend': min_budget_constraint,
                    'max_spend': filtered_df['total_spend'].max(),
                    'bottom_3_avg': bottom_3_avg if len(non_zero_spends) >= 3 else min_budget_constraint
                }
            elif model_type == 'gam':
                if len(filtered_df) < 10:
                    continue
                gam = train_gam_model(X_gam, y_data)
                model_params[channel_name] = {
                    'model_type': 'gam',
                    'gam_model': gam,
                    'min_spend': min_budget_constraint,
                    'max_spend': filtered_df['total_spend'].max(),
                    'bottom_3_avg': bottom_3_avg if len(non_zero_spends) >= 3 else min_budget_constraint
                }
        except Exception as e:
            st.warning(f"åª’ä½“ {channel_name} ã®å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return model_params

def train_models_with_uncertainty(df, config):
    """ä¸ç¢ºå®Ÿæ€§æƒ…å ±ã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆHill/Linear/GAMå¯¾å¿œï¼‰"""
    model_results = {}
    
    for channel_name, cfg in config.items():
        model_type = cfg.get('model_type', 'linear')
        
        start_date = pd.to_datetime(cfg['start_date'])
        end_date = pd.to_datetime(cfg['end_date'])
        filtered_df = df[(df['channel'] == channel_name) & 
                        (df['week_start_date'] >= start_date) & 
                        (df['week_start_date'] <= end_date)].copy()
        
        if len(filtered_df) < 10:
            continue
        
        x_data = filtered_df['total_spend'].values
        y_data = filtered_df[cfg['target_variable']].values
        X_gam = filtered_df[['total_spend']]
        
        try:
            if model_type == 'hill':
                trace = train_hill_model(x_data, y_data)
                model_results[channel_name] = {
                    'model_type': 'hill',
                    'trace': trace
                }
            elif model_type == 'linear':
                trace = train_linear_model(x_data, y_data)
                model_results[channel_name] = {
                    'model_type': 'linear',
                    'trace': trace
                }
            elif model_type == 'gam':
                spend_range = np.linspace(X_gam.values.min(), X_gam.values.max(), 100)
                n_bootstraps = 200
                bootstrap_preds = []
                
                progress = st.progress(0, text=f"{channel_name}: ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ä¸­...")
                for i in range(n_bootstraps):
                    if (i + 1) % 20 == 0:
                        progress.progress((i + 1) / n_bootstraps)
                    resampled_indices = np.random.choice(X_gam.index, size=len(X_gam), replace=True)
                    X_boot = X_gam.loc[resampled_indices]
                    y_boot = y_data[X_gam.index.get_indexer(resampled_indices)]
                    gam_boot = train_gam_model(X_boot, y_boot)
                    pred_boot = gam_boot.predict(spend_range.reshape(-1, 1))
                    bootstrap_preds.append(pred_boot)
                
                progress.empty()
                
                bootstrap_preds = np.array(bootstrap_preds)
                lower_bound = np.percentile(bootstrap_preds, 2.5, axis=0)
                upper_bound = np.percentile(bootstrap_preds, 97.5, axis=0)
                intervals = np.c_[lower_bound, upper_bound]
                final_gam = train_gam_model(X_gam, y_data)
                
                model_results[channel_name] = {
                    'model_type': 'gam',
                    'gam_model': final_gam,
                    'spend_range': spend_range,
                    'intervals': intervals
                }
        except Exception as e:
            st.warning(f"åª’ä½“ {channel_name} ã®å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return model_results

def simulate_scenarios(trained_models, scenario1_ratios, scenario2_ratios, total_budget, n_samples=5000):
    """2ã¤ã®ã‚·ãƒŠãƒªã‚ªã‚’ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æ¯”è¼ƒï¼ˆåª’ä½“åˆ¥è©³ç´°ä»˜ãï¼‰"""
    channels = list(trained_models.keys())
    
    def normalize_ratios(ratios):
        total_ratio = sum(ratios.get(ch, 0) for ch in channels)
        if total_ratio > 0 and not np.isclose(total_ratio, 1.0):
            return {ch: ratios.get(ch, 0) / total_ratio for ch in channels}
        return ratios
    
    scenario1_ratios = normalize_ratios(scenario1_ratios)
    scenario2_ratios = normalize_ratios(scenario2_ratios)
    
    s1_revenues = []
    s2_revenues = []
    
    # â˜…â˜…â˜… åª’ä½“åˆ¥ã®çµæœã‚’ä¿å­˜ã™ã‚‹è¾æ›¸ã‚’è¿½åŠ  â˜…â˜…â˜…
    s1_channel_revenues = {ch: [] for ch in channels}
    s2_channel_revenues = {ch: [] for ch in channels}
    # â˜…â˜…â˜… ã“ã“ã¾ã§è¿½åŠ  â˜…â˜…â˜…
    
    progress_bar = st.progress(0, text=f"{n_samples}å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
    
    for i in range(n_samples):
        if (i + 1) % (n_samples // 10) == 0:
            progress_bar.progress((i + 1) / n_samples)
        
        s1_total = 0
        s2_total = 0
        
        for ch in channels:
            params = trained_models[ch]
            s1_budget = scenario1_ratios.get(ch, 0) * total_budget
            s2_budget = scenario2_ratios.get(ch, 0) * total_budget
            
            # â˜…â˜…â˜… åª’ä½“åˆ¥ã®äºˆæ¸¬å€¤ã‚’è¨ˆç®—ã—ã¦ä¿å­˜ â˜…â˜…â˜…
            s1_revenue_ch = 0
            s2_revenue_ch = 0
            
            if params['model_type'] == 'hill':
                trace = params['trace']
                posterior_samples = az.extract(trace, num_samples=1)
                vmax = posterior_samples['Vmax'].item()
                ec50 = posterior_samples['EC50'].item()
                s1_revenue_ch = max(0, vmax * s1_budget / (ec50 + s1_budget + 1e-9))
                s2_revenue_ch = max(0, vmax * s2_budget / (ec50 + s2_budget + 1e-9))
                
            elif params['model_type'] == 'linear':
                trace = params['trace']
                posterior_samples = az.extract(trace, num_samples=1)
                alpha = posterior_samples['alpha'].item()
                beta = posterior_samples['beta'].item()
                s1_revenue_ch = max(0, alpha + beta * s1_budget)
                s2_revenue_ch = max(0, alpha + beta * s2_budget)
                
            elif params['model_type'] == 'gam':
                gam_model = params['gam_model']
                spend_range = params['spend_range']
                intervals = params['intervals']
                
                for budget in [s1_budget, s2_budget]:
                    idx = np.argmin(np.abs(spend_range - budget))
                    mean_pred = gam_model.predict(np.array([[budget]]))[0]
                    lower, upper = intervals[idx]
                    std_dev = (upper - lower) / 4.0
                    sample = np.random.normal(mean_pred, max(std_dev, 1e-9))
                    if budget == s1_budget:
                        s1_revenue_ch = max(0, sample)
                    else:
                        s2_revenue_ch = max(0, sample)
            
            # åª’ä½“åˆ¥ã®çµæœã‚’ä¿å­˜
            s1_channel_revenues[ch].append(s1_revenue_ch)
            s2_channel_revenues[ch].append(s2_revenue_ch)
            
            # å…¨ä½“ã®åˆè¨ˆã«åŠ ç®—
            s1_total += s1_revenue_ch
            s2_total += s2_revenue_ch
            # â˜…â˜…â˜… ã“ã“ã¾ã§ä¿®æ­£ â˜…â˜…â˜…
        
        s1_revenues.append(s1_total)
        s2_revenues.append(s2_total)
    
    progress_bar.empty()
    
    # â˜…â˜…â˜… åª’ä½“åˆ¥çµæœã‚‚è¿”ã™ â˜…â˜…â˜…
    return (np.array(s1_revenues), np.array(s2_revenues), 
            {ch: np.array(vals) for ch, vals in s1_channel_revenues.items()},
            {ch: np.array(vals) for ch, vals in s2_channel_revenues.items()})

def optimize_budget_allocation(model_params, total_budget, priority_channels, priority_ratio, n_starts):
    """äºˆç®—é…åˆ†æœ€é©åŒ–ï¼ˆãƒãƒ«ãƒã‚¹ã‚¿ãƒ¼ãƒˆæ³•ï¼‰"""
    channels = list(model_params.keys())
    n_channels = len(channels)
    
    def objective_function(budgets):
        total_revenue = 0
        for i, channel in enumerate(channels):
            params = model_params[channel]
            budget = budgets[i]
            revenue = 0
            
            if params['model_type'] == 'hill':
                vmax = params['vmax_mean']
                ec50 = params['ec50_mean']
                revenue = vmax * budget / (ec50 + budget + 1e-9)
            elif params['model_type'] == 'linear':
                alpha = params['alpha_mean']
                beta = params['beta_mean']
                revenue = alpha + beta * budget
            elif params['model_type'] == 'gam':
                revenue = params['gam_model'].predict(np.array([[budget]]))[0]
            
            total_revenue += max(0, revenue)
        return -total_revenue
    
    cons1 = {'type': 'eq', 'fun': lambda budgets: np.sum(budgets) - total_budget}
    priority_indices = [i for i, ch in enumerate(channels) if ch in priority_channels]
    cons2 = {'type': 'eq', 'fun': lambda budgets: np.sum(budgets[priority_indices]) - total_budget * priority_ratio}
    constraints = [cons1, cons2] if priority_channels else [cons1]

    # â˜…â˜…â˜… ã‚­ãƒ£ãƒªã‚¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®äºˆç®—ä¸Šé™åˆ¶ç´„ã‚’è¿½åŠ  â˜…â˜…â˜…
    if 'ã‚­ãƒ£ãƒªã‚¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹' in channels:
        career_index_idx = channels.index('ã‚­ãƒ£ãƒªã‚¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')
        career_index_budget_limit = 10000000
        cons_career_index = {'type': 'ineq', 'fun': lambda budgets: career_index_budget_limit - budgets[career_index_idx]}
        constraints.append(cons_career_index)
        st.info(f"ğŸ”’ åˆ¶ç´„ã‚’è¿½åŠ : ã‚­ãƒ£ãƒªã‚¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®äºˆç®— â‰¤ Â¥{career_index_budget_limit:,.0f}")
    
    bounds = []
    for channel in channels:
        params = model_params[channel]
        bounds.append((params['min_spend'], params['max_spend']))
    
    best_result = None
    best_fun_value = float('inf')
    
    progress_bar = st.progress(0)
    for i in range(n_starts):
        if (i + 1) % (n_starts // 10) == 0:
            progress_bar.progress((i + 1) / n_starts)
        
        random_values = np.random.rand(n_channels)
        initial_guess = (random_values / random_values.sum()) * total_budget
        
        try:
            result = minimize(objective_function, initial_guess, method='SLSQP', 
                            bounds=bounds, constraints=constraints, options={'disp': False})
            if result.success and result.fun < best_fun_value:
                best_fun_value = result.fun
                best_result = result
        except:
            pass
    
    progress_bar.empty()
    return best_result, channels

# ========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# ========================================
st.sidebar.title("ğŸ“Š åºƒå‘Šæœ€é©åŒ–ãƒ„ãƒ¼ãƒ«")

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
data_path = st.secrets.get("data_path", None)

if data_path:
    if st.session_state.combined_df is None:
        try:
            st.session_state.combined_df = pd.read_csv(data_path)
            st.session_state.combined_df['week_start_date'] = pd.to_datetime(st.session_state.combined_df['week_start_date'])
            st.sidebar.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº† ({len(st.session_state.combined_df)}è¡Œ)")
        except Exception as e:
            st.sidebar.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
else:
    uploaded_file = st.sidebar.file_uploader(
        "CSVãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['csv'],
        help="combined_dfã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_file is not None:
        try:
            st.session_state.combined_df = pd.read_csv(uploaded_file)
            st.session_state.combined_df['week_start_date'] = pd.to_datetime(st.session_state.combined_df['week_start_date'])
            st.sidebar.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº† ({len(st.session_state.combined_df)}è¡Œ)")
        except Exception as e:
            st.sidebar.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

page = st.sidebar.radio(
    "åˆ†æãƒ¡ãƒ‹ãƒ¥ãƒ¼",
    ["ğŸ“ˆ ç¾çŠ¶æŠŠæ¡", "ğŸ¯ æŠ•è³‡è²»ç”¨æœ€é©åŒ–", "ğŸ” äº‹å‰åŠ¹æœæ¤œè¨¼(å‰åŠ)", "ğŸ“Š äº‹å‰åŠ¹æœæ¤œè¨¼(å¾ŒåŠ)"],
    key="main_navigation"
)

st.sidebar.markdown("---")
st.sidebar.info("ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ—¥: 2025å¹´10æœˆ1æ—¥\nãƒ‡ãƒ¼ã‚¿æœŸé–“: 2024å¹´1æœˆ - 2025å¹´9æœˆ")

# ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
if st.session_state.combined_df is None:
    st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

df = st.session_state.combined_df
available_channels = df['channel'].unique().tolist()

# ãƒ‡ãƒ¼ã‚¿ã®æœ€æ–°æ—¥ã‚’å–å¾—ã—ã€4ãƒ¶æœˆå‰ã®æ—¥ä»˜ã‚’è¨ˆç®—
if not df.empty and 'week_start_date' in df.columns:
    latest_date = pd.to_datetime(df['week_start_date']).max()
    four_months_ago = latest_date - pd.DateOffset(months=4)
    default_start_date = four_months_ago.date()
    default_end_date = latest_date.date()
else:
    default_start_date = pd.to_datetime("2024-01-01").date()
    default_end_date = pd.to_datetime("2025-09-30").date()

# ========================================
# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
# ========================================

if page == "ğŸ“ˆ ç¾çŠ¶æŠŠæ¡":
    st.markdown('<div class="main-header">ç¾çŠ¶æŠŠæ¡</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">åª’ä½“åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="info-box">ğŸ’¡ å„åª’ä½“ã”ã¨ã«å­¦ç¿’æœŸé–“ã‚„ç›®çš„å¤‰æ•°ã‚’å€‹åˆ¥ã«è¨­å®šã—ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºèªã§ãã¾ã™</div>', unsafe_allow_html=True)
    
    selected_channels = st.multiselect(
        "åˆ†æã™ã‚‹åª’ä½“ã‚’é¸æŠ",
        available_channels,
        default=available_channels[:5] if len(available_channels) >= 5 else available_channels,
        key="status_channels"
    )
    
    if not selected_channels:
        st.warning("åª’ä½“ã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.stop()
    
    st.subheader("åª’ä½“åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
    
    with st.expander("ğŸ“ ä¸€æ‹¬è¨­å®š", expanded=False):
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            bulk_start = st.date_input("å­¦ç¿’æœŸé–“(é–‹å§‹)", value=default_start_date, key="bulk_start")
        with col2:
            bulk_end = st.date_input("å­¦ç¿’æœŸé–“(çµ‚äº†)", value=default_end_date, key="bulk_end")
        with col3:
            available_targets = [col for col in df.columns if 'å¿œå‹Ÿ' in col or 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³' in col]
            bulk_target = st.selectbox("ç›®çš„å¤‰æ•°", available_targets, key="bulk_target")
        with col4:
            bulk_model = st.selectbox("å›å¸°ãƒ¢ãƒ‡ãƒ«", ["Hill Model", "ç·šå½¢å›å¸°"], key="bulk_model")
        
        if st.button("å…¨åª’ä½“ã«é©ç”¨", key="apply_bulk"):
            for ch in selected_channels:
                st.session_state[f"status_{ch}_start"] = bulk_start
                st.session_state[f"status_{ch}_end"] = bulk_end
                st.session_state[f"status_{ch}_target"] = bulk_target
                st.session_state[f"status_{ch}_model"] = bulk_model
            st.success("è¨­å®šã‚’å…¨åª’ä½“ã«é©ç”¨ã—ã¾ã—ãŸ!")
            st.rerun()
    
    config = {}
    for channel in selected_channels:
        with st.expander(f"ğŸ“Œ {channel}", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                start_date = st.date_input(
                    "å­¦ç¿’æœŸé–“(é–‹å§‹)",
                    value=st.session_state.get(f"status_{channel}_start", default_start_date),
                    key=f"status_{channel}_start"
                )
            
            with col2:
                end_date = st.date_input(
                    "å­¦ç¿’æœŸé–“(çµ‚äº†)",
                    value=st.session_state.get(f"status_{channel}_end", default_end_date),
                    key=f"status_{channel}_end"
                )
            
            with col3:
                target_var = st.selectbox(
                    "ç›®çš„å¤‰æ•°",
                    available_targets,
                    index=0,
                    key=f"status_{channel}_target"
                )
            
            with col4:
                model_type = st.selectbox(
                    "å›å¸°ãƒ¢ãƒ‡ãƒ«",
                    ["Hill Model", "ç·šå½¢å›å¸°"],
                    key=f"status_{channel}_model"
                )
            
            config[channel] = {
                'start_date': start_date,
                'end_date': end_date,
                'target_variable': target_var,
                'model_type': 'hill' if model_type == "Hill Model" else 'linear'
            }
    
    if st.button("å…¨åª’ä½“ã®åˆ†æã‚’å®Ÿè¡Œ", type="primary", key="run_analysis"):
        st.session_state.all_channel_results = []
        st.session_state.trained_models = {}
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, channel in enumerate(selected_channels):
            status_text.text(f"åˆ†æä¸­: {channel} ({i+1}/{len(selected_channels)})")
            
            fig, r2, result = analyze_channel(df, channel, config[channel])
            
            if result:
                st.session_state.trained_models[channel] = {
                    'fig': fig,
                    'r2': r2,
                    'config': config[channel]
                }
                if result['model_type'] == 'hill':
                    st.session_state.all_channel_results.append(result)
            
            progress_bar.progress((i + 1) / len(selected_channels))
        
        status_text.text("åˆ†æå®Œäº†!")
        st.success("âœ… å…¨åª’ä½“ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ!")
        st.rerun()
    
    if st.session_state.trained_models:
        avg_r2 = np.mean([v['r2'] for v in st.session_state.trained_models.values()])
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¹³å‡ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ (RÂ²)", f"{avg_r2:.3f}", help="å…¨åª’ä½“ã®å¹³å‡å€¤")
        
        st.subheader("åª’ä½“åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        tabs = st.tabs(selected_channels)
        
        for i, tab in enumerate(tabs):
            with tab:
                channel = selected_channels[i]
                if channel in st.session_state.trained_models:
                    model_info = st.session_state.trained_models[channel]
                    st.plotly_chart(model_info['fig'], use_container_width=True)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("RÂ²ã‚¹ã‚³ã‚¢", f"{model_info['r2']:.3f}")
                    with col2:
                        st.metric("ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—", model_info['config']['model_type'].upper())
                else:
                    st.info("ã“ã®åª’ä½“ã®åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        
        if st.session_state.all_channel_results:
            st.subheader("å…¨åª’ä½“æ¯”è¼ƒ(Hillé–¢æ•°æ›²ç·š)")
            st.markdown('<div class="info-box">ğŸ’¡ å„åª’ä½“ã®Hillé–¢æ•°ã‚’åŒä¸€ç©ºé–“ã«ãƒ—ãƒ­ãƒƒãƒˆã—ã€è²»ç”¨å¯¾åŠ¹æœã‚’ä¸€ç›®ã§æ¯”è¼ƒã§ãã¾ã™</div>', unsafe_allow_html=True)
            
            max_spend = df[df['channel'].isin([r['channel'] for r in st.session_state.all_channel_results])]['total_spend'].max()
            x_range = np.linspace(0, max_spend * 1.1, 200)
            
            combined_fig = plot_combined_hill_curves(st.session_state.all_channel_results, x_range)
            st.plotly_chart(combined_fig, use_container_width=True)
            
            st.markdown("""
            <div class="warning-box">
            <strong>ğŸ“Š è§£é‡ˆ:</strong> æ›²ç·šãŒå·¦ä¸Šã«ã‚ã‚‹ã»ã©ã€ä½äºˆç®—ã§é«˜ã„åŠ¹æœã‚’å¾—ã‚‰ã‚Œã‚‹åª’ä½“ã§ã™ã€‚
            æœ€ã‚‚è²»ç”¨å¯¾åŠ¹æœãŒé«˜ã„åª’ä½“ã‹ã‚‰é †ã«æŠ•è³‡ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("ã€Œå…¨åª’ä½“ã®åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")

elif page == "ğŸ¯ æŠ•è³‡è²»ç”¨æœ€é©åŒ–":
    st.markdown('<div class="main-header">æŠ•è³‡è²»ç”¨æœ€é©åŒ–</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">äºˆç®—é…åˆ†æœ€é©åŒ–</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="info-box">ğŸ’¡ Hill/Linear/GAMãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ãŸäºˆç®—é…åˆ†æœ€é©åŒ–ã‚’è¡Œã„ã¾ã™</div>', unsafe_allow_html=True)
    
    st.subheader("æœ€é©åŒ–å¯¾è±¡åª’ä½“ã®é¸æŠã¨è¨­å®š")
    
    opt_channels = st.multiselect(
        "æœ€é©åŒ–å¯¾è±¡ã®åª’ä½“ã‚’é¸æŠ",
        available_channels,
        default=available_channels[:6] if len(available_channels) >= 6 else available_channels,
        key="opt_channels"
    )
    
    if not opt_channels:
        st.warning("æœ€é©åŒ–å¯¾è±¡ã®åª’ä½“ã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.stop()
    
    st.subheader("å„åª’ä½“ã®ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    with st.expander("ğŸ“ ä¸€æ‹¬è¨­å®š", expanded=False):
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            bulk_start = st.date_input("å­¦ç¿’æœŸé–“(é–‹å§‹)", value=default_start_date, key="opt_bulk_start")
        with col2:
            bulk_end = st.date_input("å­¦ç¿’æœŸé–“(çµ‚äº†)", value=default_end_date, key="opt_bulk_end")
        with col3:
            available_targets = [col for col in df.columns if 'å¿œå‹Ÿ' in col or 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³' in col]
            bulk_target = st.selectbox("ç›®çš„å¤‰æ•°", available_targets, key="opt_bulk_target")
        with col4:
            bulk_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—", ["Hill Model", "ç·šå½¢å›å¸°", "GAM"], key="opt_bulk_model")
        
        if st.button("å…¨åª’ä½“ã«é©ç”¨", key="apply_opt_bulk"):
            for ch in opt_channels:
                st.session_state[f"opt_{ch}_start"] = bulk_start
                st.session_state[f"opt_{ch}_end"] = bulk_end
                st.session_state[f"opt_{ch}_target"] = bulk_target
                model_map = {"Hill Model": "hill", "ç·šå½¢å›å¸°": "linear", "GAM": "gam"}
                st.session_state[f"opt_{ch}_model"] = bulk_model
            st.success("è¨­å®šã‚’å…¨åª’ä½“ã«é©ç”¨ã—ã¾ã—ãŸ!")
            st.rerun()
    
    opt_config = {}
    
    for channel in opt_channels:
        with st.expander(f"ğŸ“Œ {channel}", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                start_date = st.date_input(
                    "å­¦ç¿’æœŸé–“(é–‹å§‹)",
                    value=st.session_state.get(f"opt_{channel}_start", default_start_date),
                    key=f"opt_{channel}_start"
                )
            
            with col2:
                end_date = st.date_input(
                    "å­¦ç¿’æœŸé–“(çµ‚äº†)",
                    value=st.session_state.get(f"opt_{channel}_end", default_end_date),
                    key=f"opt_{channel}_end"
                )
            
            with col3:
                available_targets = [col for col in df.columns if 'å¿œå‹Ÿ' in col or 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³' in col]
                target_var = st.selectbox(
                    "ç›®çš„å¤‰æ•°",
                    available_targets,
                    index=0,
                    key=f"opt_{channel}_target"
                )
            
            with col4:
                model_type = st.selectbox(
                    "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
                    ["Hill Model", "ç·šå½¢å›å¸°", "GAM"],
                    key=f"opt_{channel}_model"
                )
            
            model_map = {"Hill Model": "hill", "ç·šå½¢å›å¸°": "linear", "GAM": "gam"}
            opt_config[channel] = {
                'start_date': start_date,
                'end_date': end_date,
                'target_variable': target_var,
                'model_type': model_map[model_type]
            }
    
    st.subheader("æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    col1, col2 = st.columns(2)
    
    with col1:
        total_budget = st.number_input(
            "é€±å½“ãŸã‚Šã®ç·äºˆç®— (å††)",
            min_value=0,
            value=30000000,
            step=1000000,
            format="%d",
            key="opt_budget"
        )
    
    with col2:
        n_starts = st.slider(
            "ãƒãƒ«ãƒã‚¹ã‚¿ãƒ¼ãƒˆè©¦è¡Œå›æ•°",
            10, 5000, 1000,
            help="å¤šã„ã»ã©ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ãŒæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™",
            key="opt_nstarts"
        )
    
    with st.expander("ğŸ¯ å„ªå…ˆåª’ä½“è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            priority_channels = st.multiselect(
                "å„ªå…ˆåª’ä½“ã‚’é¸æŠ",
                opt_channels,
                key="opt_priority_channels"
            )
        with col2:
            priority_ratio = st.number_input(
                "å„ªå…ˆåª’ä½“ã¸ã®é…åˆ†æ¯”ç‡",
                min_value=0.0,
                max_value=1.0,
                value=0.800,
                step=0.0001, 
                format="%.4f",
                key="opt_priority_ratio" 
            )
    
    if st.button("æœ€é©é…åˆ†ã‚’è¨ˆç®—", type="primary", key="run_optimization"):
        with st.spinner("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­..."):
            model_params = train_optimization_models(df, opt_config)
        
        if not model_params:
            st.error("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        st.success(f"âœ… {len(model_params)}åª’ä½“ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        
        with st.spinner(f"{n_starts}å›ã®æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­..."):
            result, channels = optimize_budget_allocation(
                model_params, 
                total_budget, 
                priority_channels if priority_channels else [],
                priority_ratio if priority_channels else 0,
                n_starts
            )
        
        if result and result.success:
            st.session_state.optimization_result = {
                'budgets': result.x,
                'channels': channels,
                'total_revenue': -result.fun,
                'model_params': model_params
            }
            st.success("âœ… æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ!")
            st.rerun()
        else:
            st.error("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    
    if st.session_state.optimization_result:
        st.subheader("æœ€é©äºˆç®—é…åˆ†çµæœ")
        
        result_data = st.session_state.optimization_result
        optimal_budgets = result_data['budgets']
        channels = result_data['channels']
        model_params = result_data['model_params']
        
        predicted_revenues = []
        for i, ch in enumerate(channels):
            budget = optimal_budgets[i]
            params = model_params[ch]
            
            if params['model_type'] == 'hill':
                revenue = params['vmax_mean'] * budget / (params['ec50_mean'] + budget + 1e-9)
            elif params['model_type'] == 'linear':
                revenue = params['alpha_mean'] + params['beta_mean'] * budget
            elif params['model_type'] == 'gam':
                revenue = params['gam_model'].predict(np.array([[budget]]))[0]
            
            predicted_revenues.append(max(0, revenue))
        
        result_df = pd.DataFrame({
            'é †ä½': range(len(channels)),
            'åª’ä½“': channels,
            'ãƒ¢ãƒ‡ãƒ«': [model_params[ch]['model_type'].upper() for ch in channels],
            'æœ€é©é…åˆ†äºˆç®—': optimal_budgets,
            'æœ€ä½äºˆç®—åˆ¶ç´„': [model_params[ch].get('bottom_3_avg', model_params[ch]['min_spend']) for ch in channels],
            'äºˆç®—æ¯”ç‡': optimal_budgets / total_budget,
            'äºˆæ¸¬æˆæœ': predicted_revenues
        })
        
        result_df = result_df.sort_values('æœ€é©é…åˆ†äºˆç®—', ascending=False).reset_index(drop=True)
        result_df['é †ä½'] = range(len(result_df))
        
        display_df = result_df.copy()
        display_df['æœ€é©é…åˆ†äºˆç®—'] = display_df['æœ€é©é…åˆ†äºˆç®—'].apply(lambda x: f"Â¥{x:,.0f}")
        display_df['æœ€ä½äºˆç®—åˆ¶ç´„'] = display_df['æœ€ä½äºˆç®—åˆ¶ç´„'].apply(lambda x: f"Â¥{x:,.0f}")
        display_df['äºˆç®—æ¯”ç‡'] = display_df['äºˆç®—æ¯”ç‡'].apply(lambda x: f"{x:.1%}")
        display_df['äºˆæ¸¬æˆæœ'] = display_df['äºˆæ¸¬æˆæœ'].apply(lambda x: f"{x:,.1f}")
        
        st.dataframe(display_df, use_container_width=True, hide_index=True)
        
        st.info("ğŸ’¡ **æœ€ä½äºˆç®—åˆ¶ç´„**: å„åª’ä½“ã®éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰0å††ã‚’é™¤ã„ãŸä¸‹ä½3ã¤ã®å¹³å‡é‡‘é¡ã€‚ã™ã¹ã¦ã®åª’ä½“ã§ã“ã®é‡‘é¡ä»¥ä¸ŠãŒé…åˆ†ã•ã‚Œã¾ã™ã€‚")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("äºˆæ¸¬åˆè¨ˆæˆæœ", f"{result_data['total_revenue']:,.0f}")
        with col2:
            st.metric("é…åˆ†åª’ä½“æ•°", len(channels))
        with col3:
            st.metric("ç·äºˆç®—", f"Â¥{total_budget:,.0f}")
        
        st.subheader("åˆ¶ç´„å……è¶³ã®ç¢ºèª")
        constraint_check = []
        for i, ch in enumerate(channels):
            min_constraint = model_params[ch]['min_spend']
            actual_budget = optimal_budgets[i]
            is_satisfied = actual_budget >= min_constraint
            constraint_check.append({
                'åª’ä½“': ch,
                'æœ€ä½äºˆç®—åˆ¶ç´„': f"Â¥{min_constraint:,.0f}",
                'é…åˆ†äºˆç®—': f"Â¥{actual_budget:,.0f}",
                'åˆ¶ç´„å……è¶³': 'âœ…' if is_satisfied else 'âŒ'
            })
        
        check_df = pd.DataFrame(constraint_check)
        st.dataframe(check_df, use_container_width=True, hide_index=True)
        
        if all([c['åˆ¶ç´„å……è¶³'] == 'âœ…' for c in constraint_check]):
            st.success("âœ… ã™ã¹ã¦ã®åª’ä½“ã§æœ€ä½äºˆç®—åˆ¶ç´„ã‚’æº€ãŸã—ã¦ã„ã¾ã™")
        else:
            st.warning("âš ï¸ ä¸€éƒ¨ã®åª’ä½“ã§æœ€ä½äºˆç®—åˆ¶ç´„ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ç·äºˆç®—ã‚’å¢—ã‚„ã™ã‹ã€å„ªå…ˆåª’ä½“ã®è¨­å®šã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")

elif page == "ğŸ” äº‹å‰åŠ¹æœæ¤œè¨¼(å‰åŠ)":
    st.markdown('<div class="main-header">äº‹å‰åŠ¹æœæ¤œè¨¼(å‰åŠ)</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ - ãƒ™ã‚¤ã‚ºçš„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="info-box">ğŸ’¡ 2ã¤ã®äºˆç®—é…åˆ†æ¡ˆã‚’ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æ¯”è¼ƒã—ã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ã‹ç¢ºç‡çš„ã«æ¤œè¨¼ã—ã¾ã™</div>', unsafe_allow_html=True)
    
    st.subheader("æ¯”è¼ƒå¯¾è±¡åª’ä½“ã®é¸æŠ")
    comparison_channels = st.multiselect(
        "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ã®åª’ä½“ã‚’é¸æŠ",
        available_channels,
        default=available_channels[:6] if len(available_channels) >= 6 else available_channels,
        key="comparison_channels"
    )
    
    if not comparison_channels:
        st.warning("åª’ä½“ã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.stop()
    
    st.subheader("å„åª’ä½“ã®ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    with st.expander("ğŸ“ ä¸€æ‹¬è¨­å®š", expanded=False):
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            bulk_start = st.date_input("å­¦ç¿’æœŸé–“(é–‹å§‹)", value=default_start_date, key="comp_bulk_start")
        with col2:
            bulk_end = st.date_input("å­¦ç¿’æœŸé–“(çµ‚äº†)", value=default_end_date, key="comp_bulk_end")
        with col3:
            available_targets = [col for col in df.columns if 'å¿œå‹Ÿ' in col or 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³' in col]
            bulk_target = st.selectbox("ç›®çš„å¤‰æ•°", available_targets, key="comp_bulk_target")
        with col4:
            bulk_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—", ["Hill Model", "ç·šå½¢å›å¸°", "GAM"], key="comp_bulk_model")
        
        if st.button("å…¨åª’ä½“ã«é©ç”¨", key="apply_comp_bulk"):
            for ch in comparison_channels:
                st.session_state[f"comp_{ch}_start"] = bulk_start
                st.session_state[f"comp_{ch}_end"] = bulk_end
                st.session_state[f"comp_{ch}_target"] = bulk_target
                model_map = {"Hill Model": "hill", "ç·šå½¢å›å¸°": "linear", "GAM": "gam"}
                st.session_state[f"comp_{ch}_model"] = bulk_model
            st.success("è¨­å®šã‚’å…¨åª’ä½“ã«é©ç”¨ã—ã¾ã—ãŸ!")
            st.rerun()
    
    comparison_config = {}
    
    for channel in comparison_channels:
        with st.expander(f"ğŸ“Œ {channel}", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                start_date = st.date_input(
                    "å­¦ç¿’æœŸé–“(é–‹å§‹)",
                    value=st.session_state.get(f"comp_{channel}_start", default_start_date),
                    key=f"comp_{channel}_start"
                )
            
            with col2:
                end_date = st.date_input(
                    "å­¦ç¿’æœŸé–“(çµ‚äº†)",
                    value=st.session_state.get(f"comp_{channel}_end", default_end_date),
                    key=f"comp_{channel}_end"
                )
            
            with col3:
                available_targets = [col for col in df.columns if 'å¿œå‹Ÿ' in col or 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³' in col]
                target_var = st.selectbox(
                    "ç›®çš„å¤‰æ•°",
                    available_targets,
                    index=0,
                    key=f"comp_{channel}_target"
                )
            
            with col4:
                model_type = st.selectbox(
                    "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
                    ["Hill Model", "ç·šå½¢å›å¸°", "GAM"],
                    key=f"comp_{channel}_model"
                )
            
            model_map = {"Hill Model": "hill", "ç·šå½¢å›å¸°": "linear", "GAM": "gam"}
            comparison_config[channel] = {
                'start_date': start_date,
                'end_date': end_date,
                'target_variable': target_var,
                'model_type': model_map[model_type]
            }
    
    st.subheader("ç·äºˆç®—è¨­å®š")
    total_budget = st.number_input(
        "é€±å½“ãŸã‚Šã®ç·äºˆç®— (å††)",
        min_value=0,
        value=30000000,
        step=1000000,
        format="%d",
        key="comparison_budget"
    )
    
    st.subheader("2ã¤ã®ã‚·ãƒŠãƒªã‚ªã®äºˆç®—é…åˆ†")
    
    col1, col2 = st.columns(2)
    
    scenario1_ratios = {}
    scenario2_ratios = {}
    
    with col1:
        st.markdown("#### ğŸ¤– ã‚·ãƒŠãƒªã‚ª1: ã‚·ã‚¹ãƒ†ãƒ ææ¡ˆï¼ˆæœ€é©åŒ–æ¡ˆï¼‰")
        for ch in comparison_channels:
            default_ratio = round(1.0 / len(comparison_channels), 4)
            ratio = st.number_input(
                f"{ch} ã®é…åˆ†æ¯”ç‡",
                min_value=0.0,
                max_value=1.0,
                value=default_ratio,
                step=0.0001,
                format="%.4f",
                key=f"s1_ratio_{ch}"
            )
            scenario1_ratios[ch] = ratio
        
        s1_total = sum(scenario1_ratios.values())
        if not np.isclose(s1_total, 1.0):
            st.warning(f"âš ï¸ åˆè¨ˆ: {s1_total:.2%} (100%ã«ãªã‚‹ã‚ˆã†èª¿æ•´ã•ã‚Œã¾ã™)")
    
    with col2:
        st.markdown("#### ğŸ‘¤ ã‚·ãƒŠãƒªã‚ª2: ç¾å ´æ‹…å½“è€…ææ¡ˆ")
        for ch in comparison_channels:
            default_ratio = round(1.0 / len(comparison_channels), 4)
            ratio = st.number_input(
                f"{ch} ã®é…åˆ†æ¯”ç‡",
                min_value=0.0,
                max_value=1.0,
                value=default_ratio,
                step=0.0001,
                format="%.4f",
                key=f"s2_ratio_{ch}"
            )
            scenario2_ratios[ch] = ratio
        
        s2_total = sum(scenario2_ratios.values())
        if not np.isclose(s2_total, 1.0):
            st.warning(f"âš ï¸ åˆè¨ˆ: {s2_total:.2%} (100%ã«ãªã‚‹ã‚ˆã†èª¿æ•´ã•ã‚Œã¾ã™)")
    
    st.subheader("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š")
    n_samples = st.slider(
        "ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©¦è¡Œå›æ•°",
        min_value=1000,
        max_value=10000,
        value=5000,
        step=500,
        key="n_samples"
    )
    
    if st.button("ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œ", type="primary", key="run_comparison"):
        with st.spinner("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­ï¼ˆä¸ç¢ºå®Ÿæ€§æƒ…å ±ã‚’æŠ½å‡ºï¼‰..."):
            trained_models = train_models_with_uncertainty(df, comparison_config)
        
        if not trained_models:
            st.error("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        st.success(f"âœ… {len(trained_models)}åª’ä½“ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        
        with st.spinner(f"{n_samples}å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­..."):
            # â˜…â˜…â˜… åª’ä½“åˆ¥çµæœã‚‚å—ã‘å–ã‚‹ã‚ˆã†ã«ä¿®æ­£ â˜…â˜…â˜…
            s1_revenues, s2_revenues, s1_channel_revenues, s2_channel_revenues = simulate_scenarios(
                trained_models,
                scenario1_ratios,
                scenario2_ratios,
                total_budget,
                n_samples
            )
        
        st.success("âœ… ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸ!")
        
        st.session_state.comparison_result = {
            's1_revenues': s1_revenues,
            's2_revenues': s2_revenues,
            's1_channel_revenues': s1_channel_revenues,  # â˜…â˜…â˜… è¿½åŠ  â˜…â˜…â˜…
            's2_channel_revenues': s2_channel_revenues,  # â˜…â˜…â˜… è¿½åŠ  â˜…â˜…â˜…
            's1_ratios': scenario1_ratios,
            's2_ratios': scenario2_ratios,
            'total_budget': total_budget,
            'n_samples': n_samples,
            'channels': list(trained_models.keys())  # â˜…â˜…â˜… è¿½åŠ  â˜…â˜…â˜…
        }
        
        st.rerun()
    
    if 'comparison_result' in st.session_state:
        result = st.session_state.comparison_result
        s1_revenues = result['s1_revenues']
        s2_revenues = result['s2_revenues']
        
        s1_mean = np.mean(s1_revenues)
        s1_median = np.median(s1_revenues)
        s2_mean = np.mean(s2_revenues)
        s2_median = np.median(s2_revenues)
        prob_s1_wins = np.mean(s1_revenues > s2_revenues)
        
        st.subheader("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚µãƒãƒªãƒ¼")
        
        summary_df = pd.DataFrame({
            'ã‚·ãƒŠãƒªã‚ª': ['ã‚·ãƒŠãƒªã‚ª1 (ã‚·ã‚¹ãƒ†ãƒ ææ¡ˆ) ğŸ†' if prob_s1_wins > 0.5 else 'ã‚·ãƒŠãƒªã‚ª1 (ã‚·ã‚¹ãƒ†ãƒ ææ¡ˆ)', 
                        'ã‚·ãƒŠãƒªã‚ª2 (ç¾å ´ææ¡ˆ) ğŸ†' if prob_s1_wins <= 0.5 else 'ã‚·ãƒŠãƒªã‚ª2 (ç¾å ´ææ¡ˆ)',
                        'æ”¹å–„åŠ¹æœ'],
            'äºˆæ¸¬æˆæœ(æœŸå¾…å€¤)': [f'{s1_mean:,.0f}', f'{s2_mean:,.0f}', 
                               f'+{s1_mean - s2_mean:,.0f} ({(s1_mean - s2_mean) / s2_mean * 100:+.1f}%)'],
            'äºˆæ¸¬æˆæœ(ä¸­å¤®å€¤)': [f'{s1_median:,.0f}', f'{s2_median:,.0f}',
                               f'+{s1_median - s2_median:,.0f} ({(s1_median - s2_median) / s2_median * 100:+.1f}%)']
        })
        
        st.dataframe(summary_df, use_container_width=True, hide_index=True)
        
        st.markdown(f"""
        <div style='text-align: center; padding: 2rem; background: white; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin: 2rem 0;'>
            <div style='font-size: 1.2rem; color: #2c3e50; margin-bottom: 1rem;'>
                <strong>ã‚·ãƒŠãƒªã‚ª1ï¼ˆã‚·ã‚¹ãƒ†ãƒ ææ¡ˆï¼‰ãŒã‚·ãƒŠãƒªã‚ª2ï¼ˆç¾å ´ææ¡ˆï¼‰ã‚’ä¸Šå›ã‚‹ç¢ºç‡</strong>
            </div>
            <div style='font-size: 4rem; font-weight: 700; color: {"#2ecc71" if prob_s1_wins > 0.5 else "#e74c3c"}; margin: 1rem 0;'>
                {prob_s1_wins * 100:.1f}%
            </div>
            <div style='font-size: 1rem; color: #7f8c8d;'>
                {result['n_samples']:,}å›ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        st.subheader("äºˆæ¸¬æˆæœã®ç¢ºç‡åˆ†å¸ƒ")
        
        fig = go.Figure()
        
        fig.add_trace(go.Histogram(
            x=s1_revenues,
            name=f'ã‚·ãƒŠãƒªã‚ª1 (æœŸå¾…å€¤: {s1_mean:,.0f})',
            opacity=0.7,
            marker_color='#3498db',
            nbinsx=50
        ))
        
        fig.add_trace(go.Histogram(
            x=s2_revenues,
            name=f'ã‚·ãƒŠãƒªã‚ª2 (æœŸå¾…å€¤: {s2_mean:,.0f})',
            opacity=0.7,
            marker_color='#e67e22',
            nbinsx=50
        ))
        
        fig.add_vline(x=s1_mean, line_dash="dash", line_color="#3498db", 
                     annotation_text="S1å¹³å‡", annotation_position="top")
        fig.add_vline(x=s2_mean, line_dash="dash", line_color="#e67e22",
                     annotation_text="S2å¹³å‡", annotation_position="top")
        
        fig.update_layout(
            title='åˆè¨ˆæˆæœã®äºˆæ¸¬åˆ†å¸ƒ',
            xaxis_title='äºˆæ¸¬æˆæœ',
            yaxis_title='é »åº¦',
            barmode='overlay',
            template='plotly_white',
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        with st.expander("ğŸ“Š è©³ç´°ãªçµ±è¨ˆæƒ…å ±"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ã‚·ãƒŠãƒªã‚ª1ã®çµ±è¨ˆé‡**")
                st.write(f"- å¹³å‡: {s1_mean:,.0f}")
                st.write(f"- ä¸­å¤®å€¤: {s1_median:,.0f}")
                st.write(f"- æ¨™æº–åå·®: {np.std(s1_revenues):,.0f}")
                st.write(f"- 5%ç‚¹: {np.percentile(s1_revenues, 5):,.0f}")
                st.write(f"- 95%ç‚¹: {np.percentile(s1_revenues, 95):,.0f}")
            
            with col2:
                st.write("**ã‚·ãƒŠãƒªã‚ª2ã®çµ±è¨ˆé‡**")
                st.write(f"- å¹³å‡: {s2_mean:,.0f}")
                st.write(f"- ä¸­å¤®å€¤: {s2_median:,.0f}")
                st.write(f"- æ¨™æº–åå·®: {np.std(s2_revenues):,.0f}")
                st.write(f"- 5%ç‚¹: {np.percentile(s2_revenues, 5):,.0f}")
                st.write(f"- 95%ç‚¹: {np.percentile(s2_revenues, 95):,.0f}")
            # â˜…â˜…â˜… åª’ä½“åˆ¥ã®è©³ç´°åˆ†æã‚’è¿½åŠ  â˜…â˜…â˜…
        st.subheader("ğŸ“Š åª’ä½“åˆ¥ã®è©³ç´°åˆ†æ")
        
        channels = result.get('channels', [])
        s1_channel_revenues = result.get('s1_channel_revenues', {})
        s2_channel_revenues = result.get('s2_channel_revenues', {})
        
        # åª’ä½“åˆ¥ã®æ¯”è¼ƒè¡¨
        channel_comparison_data = []
        for ch in channels:
            s1_ch_mean = np.mean(s1_channel_revenues[ch])
            s2_ch_mean = np.mean(s2_channel_revenues[ch])
            s1_ch_median = np.median(s1_channel_revenues[ch])
            s2_ch_median = np.median(s2_channel_revenues[ch])
            
            s1_budget = result['s1_ratios'].get(ch, 0) * result['total_budget']
            s2_budget = result['s2_ratios'].get(ch, 0) * result['total_budget']
            
            diff_mean = s1_ch_mean - s2_ch_mean
            diff_pct = (diff_mean / s2_ch_mean * 100) if s2_ch_mean > 0 else 0
            
            prob_s1_wins = np.mean(s1_channel_revenues[ch] > s2_channel_revenues[ch])
            
            channel_comparison_data.append({
                'åª’ä½“': ch,
                'S1äºˆç®—': f'Â¥{s1_budget:,.0f}',
                'S2äºˆç®—': f'Â¥{s2_budget:,.0f}',
                'S1äºˆæ¸¬æˆæœ(å¹³å‡)': f'{s1_ch_mean:,.1f}',
                'S2äºˆæ¸¬æˆæœ(å¹³å‡)': f'{s2_ch_mean:,.1f}',
                'å·®åˆ†(å¹³å‡)': f'{diff_mean:+,.1f} ({diff_pct:+.1f}%)',
                'S1ãŒå„ªã‚Œã¦ã„ã‚‹ç¢ºç‡': f'{prob_s1_wins:.1%}'
            })
        
        channel_comp_df = pd.DataFrame(channel_comparison_data)
        st.dataframe(channel_comp_df, use_container_width=True, hide_index=True)
        
        # åª’ä½“åˆ¥ã®åˆ†å¸ƒã‚°ãƒ©ãƒ•
        st.subheader("ğŸ“ˆ åª’ä½“åˆ¥ã®äºˆæ¸¬æˆæœåˆ†å¸ƒ")
        
        # ã‚¿ãƒ–ã§åª’ä½“ã‚’åˆ‡ã‚Šæ›¿ãˆ
        channel_tabs = st.tabs(channels)
        
        for i, tab in enumerate(channel_tabs):
            with tab:
                ch = channels[i]
                s1_ch_data = s1_channel_revenues[ch]
                s2_ch_data = s2_channel_revenues[ch]
                
                fig = go.Figure()
                
                fig.add_trace(go.Histogram(
                    x=s1_ch_data,
                    name=f'ã‚·ãƒŠãƒªã‚ª1 (å¹³å‡: {np.mean(s1_ch_data):,.0f})',
                    opacity=0.7,
                    marker_color='#3498db',
                    nbinsx=50
                ))
                
                fig.add_trace(go.Histogram(
                    x=s2_ch_data,
                    name=f'ã‚·ãƒŠãƒªã‚ª2 (å¹³å‡: {np.mean(s2_ch_data):,.0f})',
                    opacity=0.7,
                    marker_color='#e67e22',
                    nbinsx=50
                ))
                
                fig.add_vline(x=np.mean(s1_ch_data), line_dash="dash", line_color="#3498db",
                             annotation_text="S1å¹³å‡", annotation_position="top")
                fig.add_vline(x=np.mean(s2_ch_data), line_dash="dash", line_color="#e67e22",
                             annotation_text="S2å¹³å‡", annotation_position="top")
                
                fig.update_layout(
                    title=f'{ch}ã®äºˆæ¸¬æˆæœåˆ†å¸ƒ',
                    xaxis_title='äºˆæ¸¬æˆæœ',
                    yaxis_title='é »åº¦',
                    barmode='overlay',
                    template='plotly_white',
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # åª’ä½“åˆ¥ã®çµ±è¨ˆæƒ…å ±
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**ã‚·ãƒŠãƒªã‚ª1ã®çµ±è¨ˆé‡**")
                    st.write(f"- å¹³å‡: {np.mean(s1_ch_data):,.1f}")
                    st.write(f"- ä¸­å¤®å€¤: {np.median(s1_ch_data):,.1f}")
                    st.write(f"- æ¨™æº–åå·®: {np.std(s1_ch_data):,.1f}")
                    st.write(f"- 5%ç‚¹: {np.percentile(s1_ch_data, 5):,.1f}")
                    st.write(f"- 95%ç‚¹: {np.percentile(s1_ch_data, 95):,.1f}")
                
                with col2:
                    st.write("**ã‚·ãƒŠãƒªã‚ª2ã®çµ±è¨ˆé‡**")
                    st.write(f"- å¹³å‡: {np.mean(s2_ch_data):,.1f}")
                    st.write(f"- ä¸­å¤®å€¤: {np.median(s2_ch_data):,.1f}")
                    st.write(f"- æ¨™æº–åå·®: {np.std(s2_ch_data):,.1f}")
                    st.write(f"- 5%ç‚¹: {np.percentile(s2_ch_data, 5):,.1f}")
                    st.write(f"- 95%ç‚¹: {np.percentile(s2_ch_data, 95):,.1f}")

elif page == "ğŸ“Š äº‹å‰åŠ¹æœæ¤œè¨¼(å¾ŒåŠ)":
    st.markdown('<div class="main-header">äº‹å‰åŠ¹æœæ¤œè¨¼(å¾ŒåŠ)</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Prophetæ™‚ç³»åˆ—äºˆæ¸¬ - äºˆæ¸¬ç²¾åº¦æ¤œè¨¼</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="info-box">ğŸ’¡ å­¦ç¿’æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ãã®Xé€±å…ˆã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒã—ã¦åŠ¹æœæ¤œè¨¼ã‚’è¡Œã„ã¾ã™</div>', unsafe_allow_html=True)
    
    # Prophetå¿…é ˆãƒã‚§ãƒƒã‚¯
    try:
        from prophet import Prophet
    except ImportError:
        st.error("âš ï¸ Prophetãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install prophet` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    # ========================================
    # Step 1: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’è¨­å®š
    # ========================================
    st.subheader("ğŸ“š Step 1: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**å­¦ç¿’æœŸé–“**")
        prophet_start_date = st.date_input(
            "å­¦ç¿’é–‹å§‹æ—¥",
            value=pd.to_datetime("2023-01-01"),
            key="prophet_start_date"
        )
        prophet_end_date = st.date_input(
            "å­¦ç¿’çµ‚äº†æ—¥",
            value=pd.to_datetime("2025-09-29"),
            key="prophet_end_date"
        )
    
    with col2:
        st.markdown("**ç›®çš„å¤‰æ•°ãƒ»åª’ä½“é¸æŠ**")
        available_targets = [col for col in df.columns if 'å¿œå‹Ÿ' in col or 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³' in col]
        prophet_target_var = st.selectbox(
            "ç›®çš„å¤‰æ•°",
            available_targets,
            key="prophet_target_var"
        )
        
        prophet_training_channels = st.multiselect(
            "å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹åª’ä½“",
            available_channels,
            default=available_channels[:9] if len(available_channels) >= 9 else available_channels,
            key="prophet_training_channels",
            help="è¤‡æ•°åª’ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆç®—ã—ã¦å­¦ç¿’ã—ã¾ã™"
        )
    
    if not prophet_training_channels:
        st.warning("å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹åª’ä½“ã‚’é¸æŠã—ã¦ãã ã•ã„")
        st.stop()
    
    # ========================================
    # Step 2: æ¤œè¨¼æœŸé–“è¨­å®š
    # ========================================
    st.subheader("ğŸ”® Step 2: æ¤œè¨¼æœŸé–“è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        n_weeks_forecast = st.number_input(
            "å­¦ç¿’çµ‚äº†æ—¥ã‹ã‚‰ä½•é€±å…ˆã¾ã§æ¤œè¨¼ã—ã¾ã™ã‹ï¼Ÿ",
            min_value=1,
            max_value=12,
            value=2,
            key="n_weeks_forecast"
        )
    
    with col2:
        # æ¤œè¨¼æœŸé–“ã®è‡ªå‹•è¨ˆç®—
        validation_start_date = pd.to_datetime(prophet_end_date) + pd.Timedelta(days=7)
        validation_end_date = validation_start_date + pd.Timedelta(days=7 * (n_weeks_forecast - 1))
        
        st.info(f"ğŸ“… æ¤œè¨¼æœŸé–“: {n_weeks_forecast}é€±é–“\n\n" + 
                f"æ¤œè¨¼é–‹å§‹æ—¥: {validation_start_date.strftime('%Y-%m-%d')}\n" +
                f"æ¤œè¨¼çµ‚äº†æ—¥: {validation_end_date.strftime('%Y-%m-%d')}\n\n" +
                "æ¤œè¨¼å¯¾è±¡é€±:\n" + 
                "\n".join([f"- ç¬¬{i+1}é€±: {(validation_start_date + pd.Timedelta(days=7*i)).strftime('%Y-%m-%d')}" 
                          for i in range(n_weeks_forecast)]))
    
    # ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª
    df_for_check = df[df['channel'].isin(prophet_training_channels)].copy()
    validation_df = df_for_check[
        (df_for_check['week_start_date'] >= validation_start_date) & 
        (df_for_check['week_start_date'] <= validation_end_date)
    ].copy()
    
    if len(validation_df) == 0:
        st.warning(f"âš ï¸ æ¤œè¨¼æœŸé–“ï¼ˆ{validation_start_date.strftime('%Y-%m-%d')} ï½ {validation_end_date.strftime('%Y-%m-%d')}ï¼‰ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.info("ğŸ’¡ æ¤œè¨¼æœŸé–“ã‚’èª¿æ•´ã™ã‚‹ã‹ã€å­¦ç¿’çµ‚äº†æ—¥ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
    else:
        # é€±ã”ã¨ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒå…¨ã¦å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        validation_weeks = pd.date_range(start=validation_start_date, end=validation_end_date, freq='W-MON')
        missing_weeks = []
        for week in validation_weeks:
            week_data = validation_df[validation_df['week_start_date'] == week]
            if len(week_data) == 0:
                missing_weeks.append(week.strftime('%Y-%m-%d'))
        
        if missing_weeks:
            st.warning(f"âš ï¸ ä»¥ä¸‹ã®é€±ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_weeks)}")
        else:
            st.success(f"âœ… æ¤œè¨¼æœŸé–“ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒç¢ºèªã§ãã¾ã—ãŸï¼ˆ{len(validation_df)}ä»¶ï¼‰")
    
    # ========================================
    # Step 3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨äºˆæ¸¬å®Ÿè¡Œ
    # ========================================
    st.markdown("---")
    st.subheader("ğŸš€ Step 3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨äºˆæ¸¬å®Ÿè¡Œ")
    
    if st.button("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨äºˆæ¸¬ã‚’å®Ÿè¡Œ", type="primary", key="run_prophet"):
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        with st.spinner("ğŸ“š Prophetãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­..."):
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            df_for_training = df[df['channel'].isin(prophet_training_channels)].copy()
            train_df = df_for_training[
                (df_for_training['week_start_date'] >= pd.to_datetime(prophet_start_date)) & 
                (df_for_training['week_start_date'] <= pd.to_datetime(prophet_end_date))
            ].copy()
            
            # é€±ã”ã¨ã«åˆç®—
            aggregated_df = train_df.groupby('week_start_date').agg(
                y=(prophet_target_var, 'sum'),
                total_spend=('total_spend', 'sum')
            ).reset_index()
            
            if len(aggregated_df) < 10:
                st.error("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒ10ä»¶æœªæº€ã§ã™ã€‚å­¦ç¿’æœŸé–“ã‚’å»¶ã°ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            # Prophetç”¨ã®ãƒ‡ãƒ¼ã‚¿æ•´å½¢
            prophet_df = aggregated_df.rename(columns={'week_start_date': 'ds'})
            scaling_factor = 1_000_000
            prophet_df['total_spend_scaled'] = prophet_df['total_spend'] / scaling_factor
            prophet_df['floor'] = 0
            cap_value = prophet_df['y'].max() * 1.2
            prophet_df['cap'] = cap_value
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            try:
                model = Prophet(
                    growth='logistic',
                    yearly_seasonality=True,
                    weekly_seasonality=True,
                    daily_seasonality=False,
                    seasonality_mode='multiplicative',
                    changepoint_prior_scale=0.01,
                    seasonality_prior_scale=5.0
                )
                model.add_regressor('total_spend_scaled', prior_scale=0.5, standardize=False, mode='multiplicative')
                model.fit(prophet_df)
                
                st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(aggregated_df)}é€±é–“ï¼‰")
                
            except Exception as e:
                st.error(f"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.stop()
        
        # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        with st.spinner("ğŸ“Š å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
            # æ¤œè¨¼æœŸé–“ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            actual_df = df_for_training[
                (df_for_training['week_start_date'] >= validation_start_date) & 
                (df_for_training['week_start_date'] <= validation_end_date)
            ].copy()
            
            if len(actual_df) == 0:
                st.error(f"æ¤œè¨¼æœŸé–“ï¼ˆ{validation_start_date.strftime('%Y-%m-%d')} ï½ {validation_end_date.strftime('%Y-%m-%d')}ï¼‰ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                st.stop()
            
            # é€±ã”ã¨ã«å®Ÿç¸¾ã‚’åˆç®—
            actual_aggregated = actual_df.groupby('week_start_date').agg(
                y_actual=(prophet_target_var, 'sum'),
                total_spend_actual=('total_spend', 'sum')
            ).reset_index()
            actual_aggregated = actual_aggregated.sort_values('week_start_date').reset_index(drop=True)
            
            st.success(f"âœ… å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†ï¼ˆ{len(actual_aggregated)}é€±é–“ï¼‰")
        
        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        with st.spinner("ğŸ”® äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­..."):
            # äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆï¼ˆå®Ÿç¸¾ã®äºˆç®—ã‚’ä½¿ç”¨ï¼‰
            future_df = pd.DataFrame({
                'ds': actual_aggregated['week_start_date'],
                'total_spend': actual_aggregated['total_spend_actual']
            })
            future_df['total_spend_scaled'] = future_df['total_spend'] / scaling_factor
            future_df['floor'] = 0
            future_df['cap'] = cap_value
            
            # äºˆæ¸¬å®Ÿè¡Œ
            forecast = model.predict(future_df)
            
            st.success("âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
        
        # ========================================
        # Step 4: çµæœã®å¯è¦–åŒ–ã¨æ¯”è¼ƒ
        # ========================================
        st.markdown("---")
        st.subheader("ğŸ“ˆ äºˆæ¸¬ã¨å®Ÿç¸¾ã®æ¯”è¼ƒ")
        
        # éå»ã®ãƒ•ã‚£ãƒƒãƒˆ
        past_forecast = model.predict(prophet_df[['ds', 'total_spend_scaled', 'floor', 'cap']])
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig = go.Figure()
        
        # å­¦ç¿’æœŸé–“ã®å®Ÿç¸¾
        fig.add_trace(go.Scatter(
            x=prophet_df['ds'],
            y=prophet_df['y'],
            mode='lines+markers',
            name='å­¦ç¿’æœŸé–“ã®å®Ÿç¸¾å€¤',
            line=dict(color='black', width=2),
            marker=dict(size=6)
        ))
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚£ãƒƒãƒˆ
        fig.add_trace(go.Scatter(
            x=past_forecast['ds'],
            y=past_forecast['yhat'],
            mode='lines',
            name='ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚£ãƒƒãƒˆ',
            line=dict(color='royalblue', width=2, dash='dot')
        ))
        
        # æ¤œè¨¼æœŸé–“ã®å®Ÿç¸¾
        fig.add_trace(go.Scatter(
            x=actual_aggregated['week_start_date'],
            y=actual_aggregated['y_actual'],
            mode='lines+markers',
            name='æ¤œè¨¼æœŸé–“ã®å®Ÿç¸¾å€¤',
            line=dict(color='green', width=3),
            marker=dict(size=10, symbol='circle')
        ))
        
        # äºˆæ¸¬å€¤
        fig.add_trace(go.Scatter(
            x=forecast['ds'],
            y=forecast['yhat'],
            mode='lines+markers',
            name='äºˆæ¸¬å€¤',
            line=dict(color='red', width=3),
            marker=dict(size=10, symbol='x')
        ))
        
        # äºˆæ¸¬ã®ä¿¡é ¼åŒºé–“
        fig.add_trace(go.Scatter(
            x=pd.concat([forecast['ds'], forecast['ds'][::-1]]),
            y=pd.concat([forecast['yhat_upper'], forecast['yhat_lower'][::-1]]),
            fill='toself',
            fillcolor='rgba(255,0,0,0.2)',
            line=dict(color='rgba(255,255,255,0)'),
            hoverinfo="skip",
            name='äºˆæ¸¬ã®95% ä¿¡é ¼åŒºé–“',
            showlegend=True
        ))
        
        # å­¦ç¿’çµ‚äº†æ—¥ã®ç¸¦ç·š
        fig.add_shape(
            type="line",
            x0=pd.to_datetime(prophet_end_date),
            x1=pd.to_datetime(prophet_end_date),
            y0=0,
            y1=1,
            yref="paper",
            line=dict(color="gray", width=2, dash="dash"),
        )
        fig.add_annotation(
            x=pd.to_datetime(prophet_end_date),
            y=1,
            yref="paper",
            text="å­¦ç¿’çµ‚äº†æ—¥",
            showarrow=False,
            xanchor="center",
            yanchor="bottom",
            bgcolor="rgba(255,255,255,0.8)",
            bordercolor="gray",
            borderwidth=1
        )
        
        fig.update_layout(
            title=f'<b>äºˆæ¸¬ç²¾åº¦æ¤œè¨¼: å­¦ç¿’æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹{n_weeks_forecast}é€±é–“å…ˆã®{prophet_target_var}äºˆæ¸¬ã¨å®Ÿç¸¾ã®æ¯”è¼ƒ</b>',
            xaxis_title='æ—¥ä»˜',
            yaxis_title=prophet_target_var,
            legend_title='å‡¡ä¾‹',
            template='plotly_white',
            hovermode='x unified',
            height=600
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ========================================
        # Step 5: ç²¾åº¦è©•ä¾¡æŒ‡æ¨™
        # ========================================
        st.subheader("ğŸ“Š äºˆæ¸¬ç²¾åº¦è©•ä¾¡")
        
        # äºˆæ¸¬ã¨å®Ÿç¸¾ã®æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        comparison_data = []
        total_actual = 0
        total_predicted = 0
        total_abs_error = 0
        total_squared_error = 0
        
        # æ—¥ä»˜ã‚’çµ±ä¸€ã—ã¦ãƒãƒ¼ã‚¸
        forecast['ds'] = pd.to_datetime(forecast['ds'])
        actual_aggregated['week_start_date'] = pd.to_datetime(actual_aggregated['week_start_date'])
        
        # æ—¥ä»˜ã§ãƒãƒ¼ã‚¸
        merged_df = forecast.merge(
            actual_aggregated,
            left_on='ds',
            right_on='week_start_date',
            how='inner'
        )
        
        if len(merged_df) == 0:
            st.warning("âš ï¸ äºˆæ¸¬ã¨å®Ÿç¸¾ã®æ—¥ä»˜ãŒä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            for idx, row in merged_df.iterrows():
                date = row['ds']
                predicted = row['yhat']
                actual = row['y_actual']
                spend = row['total_spend_actual']
                lower = row['yhat_lower']
                upper = row['yhat_upper']
                
                error = predicted - actual
                abs_error = abs(error)
                squared_error = error ** 2
                pct_error = (error / actual * 100) if actual > 0 else 0
                
                total_actual += actual
                total_predicted += predicted
                total_abs_error += abs_error
                total_squared_error += squared_error
                
                comparison_data.append({
                    'é€±': f'ç¬¬{len(comparison_data)+1}é€±',
                    'æ—¥ä»˜': date.strftime('%Y-%m-%d'),
                    'å®Ÿç¸¾å€¤': f'{actual:,.0f}',
                    'äºˆæ¸¬å€¤': f'{predicted:,.0f}',
                    'èª¤å·®': f'{error:+,.0f}',
                    'çµ¶å¯¾èª¤å·®': f'{abs_error:,.0f}',
                    'èª¤å·®ç‡ (%)': f'{pct_error:+.2f}',
                    'ä¸‹é™ (5%)': f'{lower:,.0f}',
                    'ä¸Šé™ (95%)': f'{upper:,.0f}',
                    'å®Ÿç¸¾äºˆç®—': f'Â¥{spend:,.0f}',
                    'ä¿¡é ¼åŒºé–“å†…': 'âœ…' if lower <= actual <= upper else 'âŒ'
                })
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        # ç²¾åº¦æŒ‡æ¨™ã®è¨ˆç®—
        if len(comparison_data) > 0:
            mae = total_abs_error / len(comparison_data)
            rmse = np.sqrt(total_squared_error / len(comparison_data))
            # MAPEã®è¨ˆç®—ï¼ˆmerged_dfã‹ã‚‰ç›´æ¥è¨ˆç®—ï¼‰
            if len(merged_df) > 0:
                mape_values = []
                for _, row in merged_df.iterrows():
                    actual_val = row['y_actual']
                    pred_val = row['yhat']
                    if actual_val > 0:
                        mape_values.append(abs((pred_val - actual_val) / actual_val * 100))
                mape = np.mean(mape_values) if mape_values else 0
            else:
                mape = 0
        else:
            mae = 0
            rmse = 0
            mape = 0
        
        # å…¨ä½“ã®ç²¾åº¦æŒ‡æ¨™è¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å¹³å‡çµ¶å¯¾èª¤å·® (MAE)", f"{mae:,.0f}")
        with col2:
            st.metric("äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·® (RMSE)", f"{rmse:,.0f}")
        with col3:
            st.metric("å¹³å‡çµ¶å¯¾èª¤å·®ç‡ (MAPE)", f"{mape:.2f}%")
        with col4:
            total_error_pct = ((total_predicted - total_actual) / total_actual * 100) if total_actual > 0 else 0
            st.metric("åˆè¨ˆèª¤å·®ç‡", f"{total_error_pct:+.2f}%")
        
        # ã‚µãƒãƒªãƒ¼
        st.markdown("---")
        st.subheader("ğŸ“‹ æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**å®Ÿç¸¾ã‚µãƒãƒªãƒ¼**")
            st.write(f"- å®Ÿç¸¾åˆè¨ˆ: {total_actual:,.0f}")
            st.write(f"- å®Ÿç¸¾å¹³å‡ï¼ˆé€±ï¼‰: {total_actual / len(comparison_data):,.0f}" if len(comparison_data) > 0 else "- å®Ÿç¸¾å¹³å‡ï¼ˆé€±ï¼‰: 0")
            st.write(f"- å®Ÿç¸¾äºˆç®—åˆè¨ˆ: Â¥{actual_aggregated['total_spend_actual'].sum():,.0f}")
        
        with col2:
            st.markdown("**äºˆæ¸¬ã‚µãƒãƒªãƒ¼**")
            st.write(f"- äºˆæ¸¬åˆè¨ˆ: {total_predicted:,.0f}")
            st.write(f"- äºˆæ¸¬å¹³å‡ï¼ˆé€±ï¼‰: {total_predicted / len(comparison_data):,.0f}" if len(comparison_data) > 0 else "- äºˆæ¸¬å¹³å‡ï¼ˆé€±ï¼‰: 0")
            st.write(f"- äºˆæ¸¬ç²¾åº¦: {100 - mape:.2f}%")
        
        # ä¿¡é ¼åŒºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸
        in_interval_count = sum([1 for row in comparison_data if row['ä¿¡é ¼åŒºé–“å†…'] == 'âœ…'])
        coverage_rate = (in_interval_count / len(comparison_data) * 100) if len(comparison_data) > 0 else 0
        
        st.info(f"ğŸ“Š **ä¿¡é ¼åŒºé–“ã‚«ãƒãƒ¬ãƒƒã‚¸**: {in_interval_count}/{len(comparison_data)}é€± ({coverage_rate:.1f}%) - å®Ÿç¸¾å€¤ãŒ95%ä¿¡é ¼åŒºé–“å†…ã«å…¥ã£ã¦ã„ã‚‹å‰²åˆ")
    
    # ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰
    with st.expander("â“ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰"):
        st.markdown("""
        ### Prophetæ™‚ç³»åˆ—äºˆæ¸¬ç²¾åº¦æ¤œè¨¼æ©Ÿèƒ½ã®ä½¿ã„æ–¹
        
        **Step 1: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’è¨­å®š**
        - å­¦ç¿’æœŸé–“: éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹æœŸé–“ã‚’è¨­å®š
        - ç›®çš„å¤‰æ•°: äºˆæ¸¬ã—ãŸã„æŒ‡æ¨™ï¼ˆå¿œå‹Ÿæ•°ãªã©ï¼‰ã‚’é¸æŠ
        - å­¦ç¿’åª’ä½“: è¤‡æ•°åª’ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆç®—ã—ã¦å­¦ç¿’ã—ã¾ã™
        
        **Step 2: æ¤œè¨¼æœŸé–“è¨­å®š**
        - æ¤œè¨¼é€±æ•°: å­¦ç¿’çµ‚äº†æ—¥ã‹ã‚‰ä½•é€±å…ˆã¾ã§æ¤œè¨¼ã™ã‚‹ã‹è¨­å®šï¼ˆ1ã€œ12é€±ï¼‰
        - æ¤œè¨¼æœŸé–“ã¯è‡ªå‹•çš„ã«å­¦ç¿’çµ‚äº†æ—¥ã®ç¿Œé€±ã‹ã‚‰è¨ˆç®—ã•ã‚Œã¾ã™
        
        **Step 3: å®Ÿè¡Œã¨çµæœç¢ºèª**
        - Prophetãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚Œã¾ã™
        - æ¤œè¨¼æœŸé–“ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã•ã‚Œã¾ã™
        - å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒæ¤œè¨¼æœŸé–“ã‚’äºˆæ¸¬ã—ã¾ã™
        - äºˆæ¸¬ã¨å®Ÿç¸¾ã‚’æ¯”è¼ƒã—ã¦ç²¾åº¦ã‚’è©•ä¾¡ã—ã¾ã™
        
        ### ğŸ“Š è©•ä¾¡æŒ‡æ¨™ã®èª¬æ˜
        - **MAE (å¹³å‡çµ¶å¯¾èª¤å·®)**: äºˆæ¸¬å€¤ã¨å®Ÿç¸¾å€¤ã®å·®ã®çµ¶å¯¾å€¤ã®å¹³å‡ã€‚å°ã•ã„ã»ã©è‰¯ã„
        - **RMSE (äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®)**: èª¤å·®ã®äºŒä¹—ã®å¹³å‡ã®å¹³æ–¹æ ¹ã€‚MAEã‚ˆã‚Šå¤§ããªèª¤å·®ã‚’é‡è¦–
        - **MAPE (å¹³å‡çµ¶å¯¾èª¤å·®ç‡)**: èª¤å·®ç‡ã®çµ¶å¯¾å€¤ã®å¹³å‡ã€‚100%ã«è¿‘ã„ã»ã©ç²¾åº¦ãŒä½ã„
        - **ä¿¡é ¼åŒºé–“ã‚«ãƒãƒ¬ãƒƒã‚¸**: å®Ÿç¸¾å€¤ãŒ95%ä¿¡é ¼åŒºé–“å†…ã«å…¥ã£ã¦ã„ã‚‹å‰²åˆã€‚ç†è«–çš„ã«ã¯ç´„95%ãŒç†æƒ³
        
        ### ğŸ’¡ æ´»ç”¨ã®ã‚³ãƒ„
        - å­¦ç¿’æœŸé–“ã‚’é•·ãã™ã‚‹ã¨ã€ã‚ˆã‚Šå¤šãã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã§ãã¾ã™
        - æ¤œè¨¼æœŸé–“ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
        - ä¿¡é ¼åŒºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä½ã„å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®èª¿æ•´ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
        """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.sidebar.markdown("---")
st.sidebar.caption("Â© 2025 åºƒå‘Šæœ€é©åŒ–ãƒ„ãƒ¼ãƒ«")